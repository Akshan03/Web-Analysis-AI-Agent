{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import required libraries\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from trafilatura import fetch_url, extract\n",
    "from langchain_openai import ChatOpenAI\n",
    "from duckduckgo_search import DDGS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import httpx\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from groq import Groq\n",
    "\n",
    "# Set OpenAI API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Enhanced Content Extraction\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_web_content(url: str) -> str:\n",
    "    \"\"\"Improved technical content extraction with browser headers\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "        response = httpx.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Target common content containers\n",
    "        content = soup.find(['article', 'main', 'div[class*=\"content\"]'])\n",
    "        if not content:\n",
    "            content = soup.body\n",
    "            \n",
    "        # Extract and clean text\n",
    "        text = content.get_text('\\n', strip=True)\n",
    "        return '\\n'.join([line for line in text.split('\\n') if len(line) > 40])[:15000]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching content: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Text processing and embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "def get_embeddings(text: str) -> List[float]:\n",
    "    return model.encode(text, convert_to_tensor=False).tolist()\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 1000) -> List[str]:\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Smart Relevance Detection\n",
    "def is_relevant(question: str, context: str, threshold: float = 0.5) -> bool:\n",
    "    \"\"\"Semantic relevance check using text embeddings\"\"\"\n",
    "    if not context:\n",
    "        return False\n",
    "    \n",
    "    # Encode question and chunked context\n",
    "    chunks = chunk_text(context, chunk_size=1000)\n",
    "    question_emb = model.encode(question, convert_to_tensor=False)\n",
    "    context_embs = model.encode(chunks, convert_to_tensor=False)\n",
    "    \n",
    "    # Compute similarity scores\n",
    "    similarities = cosine_similarity([question_emb], context_embs)[0]\n",
    "    \n",
    "    return any(score > threshold for score in similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Faster Answer Generation\n",
    "def answer_from_web(question: str, context: str) -> str:\n",
    "    \"\"\"Generate answer using web context with semantic relevance\"\"\"\n",
    "    chunks = chunk_text(context, chunk_size=2000)\n",
    "    relevant_chunks = []\n",
    "    \n",
    "    # Extract relevant chunks using embeddings\n",
    "    question_emb = model.encode(question, convert_to_tensor=False)\n",
    "    chunk_embs = model.encode(chunks, convert_to_tensor=False)\n",
    "    similarities = cosine_similarity([question_emb], chunk_embs)[0]\n",
    "    \n",
    "    # Select top 2 chunks by similarity\n",
    "    top_indices = sorted(range(len(similarities)), key=lambda i: -similarities[i])[:2]\n",
    "    for idx in top_indices:\n",
    "        relevant_chunks.append(chunks[idx])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following information from the web to answer the question.\n",
    "    Avoid hallucination and stick strictly to the provided context. If unsure, state that no precise information is available.\n",
    "    \n",
    "    Context:\n",
    "    ---\n",
    "    {''.join(relevant_chunks)}\n",
    "    ---\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = groq_client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            temperature=0.2,\n",
    "            max_tokens=400\n",
    "        )\n",
    "        return f\"[Web Context Answer] {response.choices[0].message.content}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating web answer: {e}\")\n",
    "        return answer_from_ddg(question)\n",
    "\n",
    "def answer_from_ddg(question: str) -> str:\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = [r for r in ddgs.text(question, max_results=5)]  # More results\n",
    "            \n",
    "        context = \"\\n\".join([f\"{r['title']}: {r['body']}\" for r in results])\n",
    "        \n",
    "        prompt = f\"\"\"Answer this question based on web search results:\n",
    "        Question: {question}\n",
    "        Search Results: {context}\n",
    "        Answer in a clear paragraph:\"\"\"\n",
    "        \n",
    "        response = groq_client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        return f\"[Web Search Answer] {response.choices[0].message.content}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in DDG answer: {e}\")\n",
    "        return \"Could not generate an answer at this time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Final Workflow Setup\n",
    "class AgentState(TypedDict):\n",
    "    url: str\n",
    "    question: str\n",
    "    content: str\n",
    "    final_answer: str\n",
    "\n",
    "def fetch_content(state: AgentState):\n",
    "    content = fetch_web_content(state[\"url\"])\n",
    "    return {\"content\": content}\n",
    "\n",
    "def generate_answer(state: AgentState):\n",
    "    question = state[\"question\"]\n",
    "    content = state[\"content\"]\n",
    "    \n",
    "    # Use entire content without truncation\n",
    "    if is_relevant(question, content):\n",
    "        return {\"final_answer\": answer_from_web(question, content)}\n",
    "    return {\"final_answer\": answer_from_ddg(question)}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"fetch_content\", fetch_content)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.set_entry_point(\"fetch_content\")\n",
    "workflow.add_edge(\"fetch_content\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://isha.sadhguru.org/yoga/new-to-yoga/what-is-yoga/\n",
      "Question: why should we do yoga?\n",
      "Content length: 15000 characters\n",
      "Semantic relevance: Yes\n",
      "Answer Source: Web Page\n",
      "\n",
      "Answer:\n",
      "[Web Context Answer] According to the provided context, yoga is not just an expression of who you are or a simple practice or exercise, but a technology and a complete path through which you can change the shape of who you are, both literally and otherwise. It is a way of being that allows you to experience everything as a part of yourself. Yoga is a method to enhance your perception and the only thing that is real is what you perceive, the rest is all made up in your head. Yoga can help you break the cycle of compulsions and patterns that you may be stuck in and allow you to move forward in a linear path instead of going round and round. Additionally, the context suggests that if you stop practicing yoga, compulsions and patterns that you thought were gone may come back, indicating that consistent practice is necessary. In summary, the context suggests that we should do yoga in order to change and shape who we are, enhance our perception, break free from cyclical patterns and compulsions, and continue to grow and move forward.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Enhanced Test Function\n",
    "def test_agent(url: str, question: str):\n",
    "    # Extract the actual URL from the input string\n",
    "    url_match = re.search(r'https?://\\S+', url)\n",
    "    url = url_match.group(0) if url_match else url\n",
    "    \n",
    "    result = agent.invoke({\n",
    "        \"url\": url,\n",
    "        \"question\": question,\n",
    "        \"content\": \"\",\n",
    "        \"final_answer\": \"\"\n",
    "    })\n",
    "    \n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Content length: {len(result['content'])} characters\")\n",
    "    print(f\"Semantic relevance: {'Yes' if is_relevant(question, result['content']) else 'No'}\")\n",
    "    print(\"Answer Source:\", \"Web Page\" if is_relevant(question, result['content']) else \"DuckDuckGo\")\n",
    "    print(\"\\nAnswer:\")\n",
    "    print(result['final_answer'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Run test\n",
    "test_agent(\n",
    "    url=\"https://isha.sadhguru.org/yoga/new-to-yoga/what-is-yoga/\",\n",
    "    question=\"why should we do yoga?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
