{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import required libraries\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from trafilatura import fetch_url, extract\n",
    "from langchain_openai import ChatOpenAI\n",
    "from duckduckgo_search import DDGS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import httpx\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")  \n",
    "groq_client = Groq(api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Enhanced Content Extraction\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_web_content(url: str) -> str:\n",
    "    \"\"\"Improved technical content extraction with browser headers\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "        response = httpx.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Target specific content containers (adjust class names as needed)\n",
    "        content = soup.find('div', class_='entry-content') or soup.find('article') or soup.find('main')\n",
    "        if not content:\n",
    "            content = soup.body\n",
    "            \n",
    "        # Extract and clean text\n",
    "        text = content.get_text('\\n', strip=True)\n",
    "        return '\\n'.join([line for line in text.split('\\n') if len(line) > 40])[:15000]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching content: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Text processing and embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "def get_embeddings(text: str) -> List[float]:\n",
    "    return model.encode(text, convert_to_tensor=False).tolist()\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 500) -> List[str]:\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Smart Relevance Detection\n",
    "def is_relevant(question: str, context: str, threshold: float = 0.6) -> float:\n",
    "    if not context:\n",
    "        return 0.0\n",
    "    \n",
    "    # Extract keywords from the question (adjust as needed)\n",
    "    question_keywords = set(question.lower().split())\n",
    "    \n",
    "    chunks = chunk_text(context, chunk_size=1000)\n",
    "    if not chunks:\n",
    "        return 0.0\n",
    "    \n",
    "    question_emb = model.encode(question, convert_to_tensor=False)\n",
    "    context_embs = model.encode(chunks, convert_to_tensor=False)\n",
    "    similarities = cosine_similarity([question_emb], context_embs)[0]\n",
    "    \n",
    "    # Get top chunk indices\n",
    "    top_indices = sorted(range(len(similarities)), key=lambda i: -similarities[i])[:2]\n",
    "    top_chunks = [chunks[i] for i in top_indices]\n",
    "    \n",
    "    # Check if any top chunk contains question keywords\n",
    "    keyword_found = any(any(kw in chunk.lower() for kw in question_keywords) for chunk in top_chunks)\n",
    "    \n",
    "    # Compute max similarity score\n",
    "    max_score = max(similarities)\n",
    "    \n",
    "    # If keywords not found, lower the score\n",
    "    if not keyword_found:\n",
    "        max_score = 0.0\n",
    "    \n",
    "    return max_score if max_score > threshold else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Faster Answer Generation\n",
    "def answer_from_web(question: str, context: str) -> str:\n",
    "    \"\"\"Generate answer using web context with semantic relevance\"\"\"\n",
    "    chunks = chunk_text(context, chunk_size=2000)\n",
    "    relevant_chunks = []\n",
    "    \n",
    "    # Extract relevant chunks using embeddings\n",
    "    question_emb = model.encode(question, convert_to_tensor=False)\n",
    "    chunk_embs = model.encode(chunks, convert_to_tensor=False)\n",
    "    similarities = cosine_similarity([question_emb], chunk_embs)[0]\n",
    "    \n",
    "    # Select top 2 chunks by similarity\n",
    "    top_indices = sorted(range(len(similarities)), key=lambda i: -similarities[i])[:2]\n",
    "    for idx in top_indices:\n",
    "        relevant_chunks.append(chunks[idx])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following information from the web to answer the question.\n",
    "    Avoid hallucination and stick strictly to the provided context. If unsure, state that no precise information is available.\n",
    "    \n",
    "    Context:\n",
    "    ---\n",
    "    {''.join(relevant_chunks)}\n",
    "    ---\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = groq_client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            temperature=0.2,\n",
    "            max_tokens=400\n",
    "        )\n",
    "        return f\"[Web Context Answer] {response.choices[0].message.content}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating web answer: {e}\")\n",
    "        return answer_from_ddg(question)\n",
    "\n",
    "def answer_from_ddg(question: str) -> str:\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = [r for r in ddgs.text(question, max_results=5)]  # More results\n",
    "            \n",
    "        context = \"\\n\".join([f\"{r['title']}: {r['body']}\" for r in results])\n",
    "        \n",
    "        prompt = f\"\"\"Answer this question based on web search results:\n",
    "        Question: {question}\n",
    "        Search Results: {context}\n",
    "        Answer in a clear paragraph:\"\"\"\n",
    "        \n",
    "        response = groq_client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        return f\"[Web Search Answer] {response.choices[0].message.content}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in DDG answer: {e}\")\n",
    "        return \"Could not generate an answer at this time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Final Workflow Setup\n",
    "class AgentState(TypedDict):\n",
    "    url: str\n",
    "    question: str\n",
    "    content: str\n",
    "    final_answer: str\n",
    "\n",
    "def fetch_content(state: AgentState):\n",
    "    content = fetch_web_content(state[\"url\"])\n",
    "    return {\"content\": content}\n",
    "\n",
    "def generate_answer(state: AgentState):\n",
    "    question = state[\"question\"]\n",
    "    content = state[\"content\"]\n",
    "    \n",
    "    # Use entire content without truncation\n",
    "    if is_relevant(question, content):\n",
    "        return {\"final_answer\": answer_from_web(question, content)}\n",
    "    return {\"final_answer\": answer_from_ddg(question)}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"fetch_content\", fetch_content)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.set_entry_point(\"fetch_content\")\n",
    "workflow.add_edge(\"fetch_content\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://isha.sadhguru.org/yoga/new-to-yoga/what-is-yoga/\n",
      "Question: How to do yoga?\n",
      "Content length: 15000 characters\n",
      "Max similarity score: 0.0000\n",
      "Answer Source: DuckDuckGo\n",
      "\n",
      "Answer:\n",
      "[Web Search Answer] To do yoga, you can start by learning the basics of yoga poses for beginners through resources such as \"31 Yoga Poses for Beginners\" on Verywell Fit. This can help you understand the poses, their benefits, and modifications if needed. Before starting, wear comfortable and lightweight clothing and find a quiet place to practice. You can begin with the child's pose, which involves kneeling on a yoga mat with your feet together, lowering your torso between your legs, and reaching your arms forward. For a more guided experience, you can follow along with videos like \"Yoga for Complete Beginners\" by Yoga With Adriene or \"10-Minute Yoga For Beginners\" on YouTube. Additionally, you can refer to \"Yoga For Beginners: A Complete Guide\" on Yoga Basics to learn about the philosophy, anatomy, therapy, and practice of yoga.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Enhanced Test Function\n",
    "def test_agent(url: str, question: str):\n",
    "    result = agent.invoke({\n",
    "        \"url\": url,\n",
    "        \"question\": question,\n",
    "        \"content\": \"\",\n",
    "        \"final_answer\": \"\"\n",
    "    })\n",
    "    \n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Content length: {len(result['content'])} characters\")\n",
    "    \n",
    "    max_score = is_relevant(question, result['content'])\n",
    "    print(f\"Max similarity score: {max_score:.4f}\")\n",
    "    \n",
    "    answer_source = \"Web Page\" if max_score > 0.6 else \"DuckDuckGo\"\n",
    "    print(f\"Answer Source: {answer_source}\")\n",
    "    \n",
    "    print(\"\\nAnswer:\")\n",
    "    print(result['final_answer'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Run test\n",
    "test_agent(\n",
    "    url=\"https://isha.sadhguru.org/yoga/new-to-yoga/what-is-yoga/\",\n",
    "    question=\"How to do yoga?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
