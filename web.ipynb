{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import required libraries\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from trafilatura import fetch_url, extract\n",
    "from langchain_openai import ChatOpenAI\n",
    "from duckduckgo_search import DDGS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import httpx\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")  \n",
    "groq_client = Groq(api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Enhanced Content Extraction\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_web_content(url: str) -> str:\n",
    "    \"\"\"Improved technical content extraction with browser headers\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "        response = httpx.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Target specific content containers (adjust class names as needed)\n",
    "        content = soup.find('div', class_='entry-content') or soup.find('article') or soup.find('main')\n",
    "        if not content:\n",
    "            content = soup.body\n",
    "            \n",
    "        # Extract and clean text\n",
    "        text = content.get_text('\\n', strip=True)\n",
    "        return '\\n'.join([line for line in text.split('\\n') if len(line) > 40])[:15000]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching content: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Text processing and embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "def get_embeddings(text: str) -> List[float]:\n",
    "    return model.encode(text, convert_to_tensor=False).tolist()\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 500) -> List[str]:\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Smart Relevance Detection\n",
    "def is_relevant(question: str, context: str, threshold: float = 0.6) -> float:\n",
    "    if not context:\n",
    "        return 0.0\n",
    "    \n",
    "    # Extract keywords from the question (adjust as needed)\n",
    "    question_keywords = set(question.lower().split())\n",
    "    \n",
    "    chunks = chunk_text(context, chunk_size=1000)\n",
    "    if not chunks:\n",
    "        return 0.0\n",
    "    \n",
    "    question_emb = model.encode(question, convert_to_tensor=False)\n",
    "    context_embs = model.encode(chunks, convert_to_tensor=False)\n",
    "    similarities = cosine_similarity([question_emb], context_embs)[0]\n",
    "    \n",
    "    # Get top chunk indices\n",
    "    top_indices = sorted(range(len(similarities)), key=lambda i: -similarities[i])[:2]\n",
    "    top_chunks = [chunks[i] for i in top_indices]\n",
    "    \n",
    "    # Check if any top chunk contains question keywords\n",
    "    keyword_found = any(any(kw in chunk.lower() for kw in question_keywords) for chunk in top_chunks)\n",
    "    \n",
    "    # Compute max similarity score\n",
    "    max_score = max(similarities)\n",
    "    \n",
    "    # If keywords not found, lower the score\n",
    "    if not keyword_found:\n",
    "        max_score = 0.0\n",
    "    \n",
    "    return max_score if max_score > threshold else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Faster Answer Generation\n",
    "def answer_from_web(question: str, context: str) -> str:\n",
    "    \"\"\"Generate answer using web context with semantic relevance\"\"\"\n",
    "    chunks = chunk_text(context, chunk_size=2000)\n",
    "    relevant_chunks = []\n",
    "    \n",
    "    # Extract relevant chunks using embeddings\n",
    "    question_emb = model.encode(question, convert_to_tensor=False)\n",
    "    chunk_embs = model.encode(chunks, convert_to_tensor=False)\n",
    "    similarities = cosine_similarity([question_emb], chunk_embs)[0]\n",
    "    \n",
    "    # Select top 4 chunks by similarity (previously 2)\n",
    "    top_indices = sorted(range(len(similarities)), key=lambda i: -similarities[i])[:4]\n",
    "    for idx in top_indices:\n",
    "        relevant_chunks.append(chunks[idx])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following information from the web to answer the question.\n",
    "    Avoid hallucination and stick strictly to the provided context. If unsure, state that no precise information is available.\n",
    "    \n",
    "    Context:\n",
    "    ---\n",
    "    {''.join(relevant_chunks)}\n",
    "    ---\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer in detail:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = groq_client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            temperature=0.2,\n",
    "            max_tokens=500  # Increased from 400\n",
    "        )\n",
    "        return f\"[Web Context Answer] {response.choices[0].message.content}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating web answer: {e}\")\n",
    "        return answer_from_ddg(question)\n",
    "\n",
    "def answer_from_ddg(question: str) -> str:\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = [r for r in ddgs.text(question, max_results=5)]  # More results\n",
    "            \n",
    "        context = \"\\n\".join([f\"{r['title']}: {r['body']}\" for r in results])\n",
    "        \n",
    "        prompt = f\"\"\"Answer this question based on web search results:\n",
    "        Question: {question}\n",
    "        Search Results: {context}\n",
    "        Answer in a clear paragraph:\"\"\"\n",
    "        \n",
    "        response = groq_client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        return f\"[Web Search Answer] {response.choices[0].message.content}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in DDG answer: {e}\")\n",
    "        return \"Could not generate an answer at this time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Final Workflow Setup\n",
    "class AgentState(TypedDict):\n",
    "    url: str\n",
    "    question: str\n",
    "    content: str\n",
    "    final_answer: str\n",
    "\n",
    "def fetch_content(state: AgentState):\n",
    "    content = fetch_web_content(state[\"url\"])\n",
    "    return {\"content\": content}\n",
    "\n",
    "def generate_answer(state: AgentState):\n",
    "    question = state[\"question\"]\n",
    "    content = state[\"content\"]\n",
    "    \n",
    "    # Use entire content without truncation\n",
    "    if is_relevant(question, content):\n",
    "        return {\"final_answer\": answer_from_web(question, content)}\n",
    "    return {\"final_answer\": answer_from_ddg(question)}\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"fetch_content\", fetch_content)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.set_entry_point(\"fetch_content\")\n",
    "workflow.add_edge(\"fetch_content\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://isha.sadhguru.org/yoga/new-to-yoga/what-is-yoga/\n",
      "Question: What is the meaning of yoga?\n",
      "Content length: 15000 characters\n",
      "Max similarity score: 0.7264\n",
      "Answer Source: Web Page\n",
      "\n",
      "Answer:\n",
      "[Web Context Answer] Yoga is a complete path by itself that signifies a technology for transformation and liberation from memory. It is not limited to physical postures or exercises, but is a way of being where one experiences everything as a part of themselves. The ultimate goal of Yoga is to move towards an experiential reality where one knows the ultimate nature of the existence.\n",
      "\n",
      "In the Yogic tradition, the word \"Yoga\" attached to anything indicates that it is a complete path by itself. This is because Yoga is not just a simple practice or an art form, but a technology that can change the shape of who you are, both literally and otherwise. It is a mechanism to get you to a state of experience where you see reality just the way it is.\n",
      "\n",
      "Yoga is also about liberating oneself from memory. It is not about expressing who you are, but about changing the shape of who you are. While other activities may leave you transformed due to absolute involvement, Yoga is a technology for transformation.\n",
      "\n",
      "In the western part of the world, the idea of Yoga is often distorted and limited to impossible physical postures. However, Yoga is about knowing the union of existence by experience. It is about realizing the oneness of existence, where every subatomic particle in your body is in constant transaction with everything else in the existence.\n",
      "\n",
      "In summary, Yoga is a complete path by itself, a technology for transformation, and a way to experience the oneness of existence. It is not limited to physical postures or exercises, but is a way of being that moves towards an experiential reality where one knows the ultimate nature of the existence.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Enhanced Test Function\n",
    "def test_agent(url: str, question: str):\n",
    "    result = agent.invoke({\n",
    "        \"url\": url,\n",
    "        \"question\": question,\n",
    "        \"content\": \"\",\n",
    "        \"final_answer\": \"\"\n",
    "    })\n",
    "    \n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Content length: {len(result['content'])} characters\")\n",
    "    \n",
    "    max_score = is_relevant(question, result['content'])\n",
    "    print(f\"Max similarity score: {max_score:.4f}\")\n",
    "    \n",
    "    answer_source = \"Web Page\" if max_score > 0.6 else \"DuckDuckGo\"\n",
    "    print(f\"Answer Source: {answer_source}\")\n",
    "    \n",
    "    print(\"\\nAnswer:\")\n",
    "    print(result['final_answer'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Run test\n",
    "test_agent(\n",
    "    url=\"https://isha.sadhguru.org/yoga/new-to-yoga/what-is-yoga/\",\n",
    "    question=\"What is the meaning of yoga?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
